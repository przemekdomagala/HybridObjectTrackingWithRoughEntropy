{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "76d2496f",
   "metadata": {},
   "source": [
    "# Gathering data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4a28a925",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np \n",
    "import os \n",
    "import pandas as pd \n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0f540d57",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = []\n",
    "input_path = 'dataset/baseline/pedestrians/input'\n",
    "\n",
    "for dirname, _, filenames in os.walk(input_path):\n",
    "    filenames.sort()  \n",
    "    for filename in filenames:\n",
    "        img_path = os.path.join(dirname, filename)\n",
    "        dataset.append(cv2.imread(img_path))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dd71bab",
   "metadata": {},
   "source": [
    "# Conversion to grayscale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "707abfa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "gray_dataset = [cv2.cvtColor(img, cv2.COLOR_BGR2GRAY) for img in dataset]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73058cf5",
   "metadata": {},
   "source": [
    "# Granule Formation with quadtree decomposition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "90d28302",
   "metadata": {},
   "outputs": [],
   "source": [
    "regions_of_interest = []\n",
    "\n",
    "def quadtree_decomposition(I, threshold, minSize, regions):\n",
    "    intensityDiff = I.max() - I.min()\n",
    "    h, w = I.shape\n",
    "\n",
    "    if intensityDiff > threshold and w > minSize:\n",
    "        for quadrant in split_image(I):\n",
    "            quadtree_decomposition(quadrant, threshold, minSize, regions)\n",
    "    else:\n",
    "        regions.append(I)\n",
    "\n",
    "def split_image(I):\n",
    "    h, w = I.shape\n",
    "    return (\n",
    "        I[0:h//2, 0:w//2],\n",
    "        I[0:h//2, w//2:],\n",
    "        I[h//2:, 0:w//2],\n",
    "        I[h//2:, w//2:]\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db920f40",
   "metadata": {},
   "source": [
    "# Rough Entropy Basen Threshold generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a9260325",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_rough_entropy_based_threshold(granules, prev_threshold=None):\n",
    "    BASE = 10\n",
    "    gray_values = [pixel for granule in granules for pixel in granule.flatten()]\n",
    "    max_gray, min_gray = int(np.max(gray_values)), int(np.min(gray_values))\n",
    "    gray_range = (max_gray - min_gray) + 1\n",
    "    offset = min_gray\n",
    "\n",
    "    object_lower = np.zeros(gray_range)\n",
    "    object_upper = np.zeros(gray_range)\n",
    "    background_lower = np.zeros(gray_range)\n",
    "    background_upper = np.zeros(gray_range)\n",
    "\n",
    "    if prev_threshold:\n",
    "        start_threshold = max(prev_threshold - 10, min_gray)\n",
    "        end_threshold = min(prev_threshold + 10, max_gray)\n",
    "    else:\n",
    "        start_threshold = min_gray\n",
    "        end_threshold = max_gray\n",
    "\n",
    "    size = granules[0].size\n",
    "\n",
    "    for g in granules:\n",
    "        g_min, g_max = int(g.min()), int(g.max())\n",
    "        for j in range(g_max, end_threshold + 1):\n",
    "            object_lower[j - offset] += size\n",
    "        for j in range(g_min, end_threshold + 1):\n",
    "            object_upper[j - offset] += size\n",
    "        for j in range(start_threshold, g_min):\n",
    "            background_lower[j - offset] += size\n",
    "        for j in range(start_threshold, g_max):\n",
    "            background_upper[j - offset] += size\n",
    "\n",
    "    entropy = np.zeros(gray_range)\n",
    "    for l in range(start_threshold, end_threshold + 1):\n",
    "        idx = l - offset\n",
    "        o_rough = 1 - (object_lower[idx] / object_upper[idx]) if object_upper[idx] != 0 else 0\n",
    "        b_rough = 1 - (background_lower[idx] / background_upper[idx]) if background_upper[idx] != 0 else 0\n",
    "\n",
    "        o_entropy = 1 if o_rough <= 1 / BASE or o_rough == 0 else o_rough * np.log(o_rough) / np.log(BASE)\n",
    "        b_entropy = 1 if b_rough <= 1 / BASE or b_rough == 0 else b_rough * np.log(b_rough) / np.log(BASE)\n",
    "        entropy[idx] = - (BASE / 2) * (o_entropy + b_entropy)\n",
    "\n",
    "    T_star = np.argmax(entropy) + offset\n",
    "    return T_star"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04ec79dc",
   "metadata": {},
   "source": [
    "# Temporal Segmentation Through Background Estimation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c969c78b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def temporal_segmentation(frame_t, f1, f2, f3, E=3):\n",
    "    f1, f2, f3 = f1.astype(np.float32), f2.astype(np.float32), f3.astype(np.float32)\n",
    "\n",
    "    optimistic = np.maximum.reduce([f1, f2, f3])\n",
    "    pessimistic = np.minimum.reduce([f1, f2, f3])\n",
    "    most_likely = np.median(np.stack([f1, f2, f3], axis=0), axis=0)\n",
    "\n",
    "    mu = (optimistic + 4 * most_likely + pessimistic) / 6\n",
    "    sigma = (optimistic - pessimistic) / 6\n",
    "    diff = np.abs(frame_t.astype(np.float32) - mu)\n",
    "\n",
    "    return diff > (E * sigma)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a444421",
   "metadata": {},
   "source": [
    "# Object tracking initialization\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5b1a81b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "def calculate_tracker_speed(center1, center2):\n",
    "    dx = center2[0] - center1[0]\n",
    "    dy = center2[1] - center1[1]\n",
    "    return math.sqrt(dx**2 + dy**2), dx, dy\n",
    "\n",
    "for frame in gray_dataset:\n",
    "    quadtree_decomposition(frame, threshold=10, minSize=10, regions=regions_of_interest)\n",
    "\n",
    "ground_truth_array = []\n",
    "gt_path = 'dataset/baseline/pedestrians/groundtruth'\n",
    "count = 0\n",
    "for dirname, _, filenames in os.walk(gt_path):\n",
    "    filenames.sort()\n",
    "    for filename in filenames:\n",
    "        if filename.endswith(('.png', '.jpg')):\n",
    "            gt_img = cv2.imread(os.path.join(dirname, filename), 0)\n",
    "            ground_truth_array.append(gt_img)\n",
    "            count += 1\n",
    "        if count >= 2:\n",
    "            break\n",
    "    if count >= 2:\n",
    "        break\n",
    "\n",
    "def get_center(mask):\n",
    "    ys, xs = np.where(mask > 0)\n",
    "    if len(xs) == 0 or len(ys) == 0:\n",
    "        return None\n",
    "    return (int(np.mean(xs)), int(np.mean(ys)))\n",
    "\n",
    "def init_tracking(gt_array):\n",
    "    if len(gt_array) < 2:\n",
    "        return None, None, None\n",
    "\n",
    "    center_t_minus_1 = get_center(gt_array[1])\n",
    "    center_t_minus_2 = get_center(gt_array[0])\n",
    "\n",
    "    if center_t_minus_1 and center_t_minus_2:\n",
    "        s, dx, dy = calculate_tracker_speed(center_t_minus_2, center_t_minus_1)\n",
    "        print(f\"[Init] speed={s:.2f}, dx={dx}, dy={dy}\")\n",
    "        return center_t_minus_2, center_t_minus_1, (dx, dy)\n",
    "    else:\n",
    "        print(\"[Init] Failed to find object centers.\")\n",
    "        return None, None, None\n",
    "    \n",
    "def compute_iou(mask_pred, mask_gt):\n",
    "    intersection = np.logical_and(mask_pred, mask_gt).sum()\n",
    "    union = np.logical_or(mask_pred, mask_gt).sum()\n",
    "    return intersection / union if union > 0 else 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cfce58e",
   "metadata": {},
   "source": [
    "# Object Tracking Iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4c4b4d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def semi_supervised_tracking(threshold=10, minSize=10, E=3):\n",
    "    tracked_frames = []\n",
    "    bounding_boxes = []\n",
    "    iou_scores = []\n",
    "    prev_threshold = None\n",
    "\n",
    "    center_t_minus_2, center_t_minus_1, motion = init_tracking(ground_truth_array)\n",
    "    prev_tracker = ground_truth_array[1]\n",
    "    prev_prev_tracker = ground_truth_array[0]\n",
    "\n",
    "    for idx in range(3, len(gray_dataset)):\n",
    "        frame = gray_dataset[idx]\n",
    "        f1, f2, f3 = gray_dataset[idx - 1], gray_dataset[idx - 2], gray_dataset[idx - 3]\n",
    "        current_color = dataset[idx]\n",
    "\n",
    "        granules = []\n",
    "        quadtree_decomposition(frame, threshold=threshold, minSize=minSize, regions=granules)\n",
    "\n",
    "        T_star = generate_rough_entropy_based_threshold(granules, prev_threshold)\n",
    "        _, spatial_segment = cv2.threshold(frame, T_star, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "        temporal_segment = temporal_segmentation(frame, f1, f2, f3, E=E).astype(np.uint8) * 255\n",
    "\n",
    "        combined_segment = cv2.bitwise_and(spatial_segment, temporal_segment)\n",
    "\n",
    "        mask_indices = np.where(combined_segment > 0)\n",
    "        if len(mask_indices[0]) == 0:\n",
    "            print(f\"[Frame {idx}] No object detected.\")\n",
    "            tracked_frames.append(current_color)\n",
    "            bounding_boxes.append(None)\n",
    "            iou_scores.append(0)\n",
    "            continue\n",
    "\n",
    "        object_pixels = current_color[mask_indices]\n",
    "        mean_color = np.mean(object_pixels, axis=0)\n",
    "        max_dev = np.std(object_pixels, axis=0)\n",
    "\n",
    "        result_mask = np.zeros_like(frame)\n",
    "        for y, x in zip(*mask_indices):\n",
    "            if np.all(np.abs(current_color[y, x] - mean_color) <= max_dev):\n",
    "                result_mask[y, x] = 255\n",
    "\n",
    "        ys, xs = np.where(result_mask > 0)\n",
    "        if len(xs) > 0 and len(ys) > 0:\n",
    "            x_min, x_max = xs.min(), xs.max()\n",
    "            y_min, y_max = ys.min(), ys.max()\n",
    "            bbox_img = cv2.rectangle(current_color.copy(), (x_min, y_min), (x_max, y_max), (0, 255, 0), 2)\n",
    "            tracked_frames.append(bbox_img)\n",
    "            bounding_boxes.append(((x_min, y_min), (x_max, y_max)))\n",
    "\n",
    "            if idx < len(ground_truth_array):\n",
    "                iou = compute_iou(result_mask > 0, ground_truth_array[idx] > 0)\n",
    "                iou_scores.append(iou)\n",
    "        else:\n",
    "            tracked_frames.append(current_color)\n",
    "            bounding_boxes.append(None)\n",
    "            iou_scores.append(0)\n",
    "\n",
    "        prev_threshold = T_star\n",
    "        prev_prev_tracker = prev_tracker\n",
    "        prev_tracker = result_mask\n",
    "\n",
    "    return tracked_frames, bounding_boxes, iou_scores\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da623786",
   "metadata": {},
   "source": [
    "# Usage\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "782eae8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Init] speed=0.00, dx=0, dy=0\n"
     ]
    }
   ],
   "source": [
    "results, bboxes, ious = semi_supervised_tracking(threshold=10, minSize=10, E=3)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
