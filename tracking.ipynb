{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38b2881e",
   "metadata": {},
   "outputs": [],
   "source": [
    "### ONLY CODE LINES YOU NEED TO EDIT TO TEST TRACKING ON PEDESTRIAN AND HIGHWAY DATASETS\n",
    "\n",
    "HIGHWAY_DIR=\"/home/przemek/studia/sp2/highway\"\n",
    "PEDESTRIAN_DIR=\"/home/przemek/studia/sp2/pedestrian\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17d4d93b",
   "metadata": {},
   "source": [
    "# Imports and config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d9649ecc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "from natsort import natsorted\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, jaccard_score\n",
    "import pandas as pd\n",
    "\n",
    "FILES_NUMBER = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d62e6fa",
   "metadata": {},
   "source": [
    "# Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "795c064f",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Environment variable 'PEDESTRIAN_DIR' is not set",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m PEDESTRIAN_DIR \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39menviron\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPEDESTRIAN_DIR\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m PEDESTRIAN_DIR \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m----> 3\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEnvironment variable \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPEDESTRIAN_DIR\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m is not set\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      5\u001b[0m HIGHWAY_DIR \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39menviron\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mHIGHWAY_DIR\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m HIGHWAY_DIR \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mValueError\u001b[0m: Environment variable 'PEDESTRIAN_DIR' is not set"
     ]
    }
   ],
   "source": [
    "gt_dir = os.path.join(PEDESTRIAN_DIR, 'groundtruth')\n",
    "frame_dir = os.path.join(PEDESTRIAN_DIR, 'input')\n",
    "\n",
    "highway_dir = os.path.join(HIGHWAY_DIR, 'input')\n",
    "gt_highway_dir = os.path.join(HIGHWAY_DIR, 'groundtruth')\n",
    "\n",
    "frame_files = natsorted([f for f in os.listdir(frame_dir) if f.endswith('.jpg')])\n",
    "frame_files = frame_files[540:]  \n",
    "\n",
    "highway_files = natsorted([f for f in os.listdir(highway_dir) if f.endswith('.jpg')])\n",
    "highway_files = highway_files[405:]\n",
    "\n",
    "gray_images_array = []\n",
    "colour_images_array = []\n",
    "gt_array = []\n",
    "\n",
    "highway_gray_images_array = []\n",
    "highway_colour_images_array = []\n",
    "highway_gt_array = []\n",
    "\n",
    "def read_images_from_directory(directory, files, gt_dir=None):\n",
    "    gray_images = []\n",
    "    colour_images = []\n",
    "    gt_images = []\n",
    "\n",
    "    for i in range(FILES_NUMBER):\n",
    "        gray = cv2.imread(os.path.join(directory, files[i]), cv2.IMREAD_GRAYSCALE)\n",
    "        colour = cv2.imread(os.path.join(directory, files[i]), cv2.IMREAD_COLOR)\n",
    "        gt = cv2.imread(os.path.join(gt_dir, files[i].replace('in', 'gt').replace('.jpg', '.png')), cv2.IMREAD_GRAYSCALE)\n",
    "        \n",
    "        gray_images.append(gray)\n",
    "        colour_images.append(colour)\n",
    "\n",
    "        ys, xs = np.where(gt == 255)\n",
    "        if len(xs) > 0 and len(ys) > 0:\n",
    "            x1, y1, x2, y2 = min(xs), min(ys), max(xs), max(ys)\n",
    "            if (x2 - x1 < 15) or (y2 - y1 < 15):\n",
    "                gt_images.append([0, 0, 0, 0])  \n",
    "            else:\n",
    "                gt_images.append([x1, y1, x2, y2])\n",
    "\n",
    "    return gray_images, colour_images, gt_images\n",
    "\n",
    "highway_gray_images_array, highway_colour_images_array, highway_gt_array = read_images_from_directory(highway_dir, highway_files, gt_highway_dir)\n",
    "gray_images_array, colour_images_array, gt_array = read_images_from_directory(frame_dir, frame_files, gt_dir)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e9ad1a5",
   "metadata": {},
   "source": [
    "# Quadtree Decomposition and ground truth computing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6c50d2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_grth(image):\n",
    "    flat = image.flatten()\n",
    "    q1 = np.percentile(flat, 25)\n",
    "    q3 = np.percentile(flat, 75)\n",
    "    return (q3 - q1) / 2\n",
    "\n",
    "def quad_tree_granulation(image, threshold=None, min_size=4):\n",
    "    h, w = image.shape\n",
    "    granules = []\n",
    "\n",
    "    if threshold is None:\n",
    "        threshold = compute_grth(image)\n",
    "\n",
    "    def divide(x, y, w_, h_):\n",
    "        if w_ <= 0 or h_ <= 0:\n",
    "            return\n",
    "        patch = image[y:y+h_, x:x+w_]\n",
    "        if patch.size == 0:\n",
    "            return\n",
    "        min_val = np.min(patch)\n",
    "        max_val = np.max(patch)\n",
    "\n",
    "        if (max_val - min_val > threshold) and (w_ > min_size and h_ > min_size):\n",
    "            hw = w_ // 2\n",
    "            hh = h_ // 2\n",
    "            divide(x, y, hw, hh)\n",
    "            divide(x + hw, y, w_ - hw, hh)\n",
    "            divide(x, y + hh, hw, h_ - hh)\n",
    "            divide(x + hw, y + hh, w_ - hw, h_ - hh)\n",
    "        else:\n",
    "            cx = x + w_ // 2\n",
    "            cy = y + h_ // 2\n",
    "            granules.append((x, y, w_, h_, cx, cy))  \n",
    "\n",
    "    divide(0, 0, w, h)\n",
    "    return granules\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e198301",
   "metadata": {},
   "source": [
    "# Quadtree decomposition test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b2c853a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_quad_tree_granulation(dir, files):\n",
    "    img_path = os.path.join(dir, files[0])\n",
    "    image = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
    "    granules = quad_tree_granulation(image)\n",
    "    image_color = cv2.cvtColor(image, cv2.COLOR_GRAY2BGR)\n",
    "    for x, y, w, h, cx, cy in granules:\n",
    "        cv2.rectangle(image_color, (x, y), (x + w, y + h), (0, 255, 0), 1)   \n",
    "        cv2.circle(image_color, (cx, cy), 1, (0, 0, 255), -1)\n",
    "    plt.figure(figsize=(10, 10))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.imshow(image, cmap='gray')\n",
    "    plt.title(\"Gray Image\")\n",
    "    plt.axis(\"off\")\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.imshow(cv2.cvtColor(image_color, cv2.COLOR_BGR2RGB))\n",
    "    plt.title(f\"Granules: {len(granules)}\")\n",
    "    plt.axis(\"off\")\n",
    "    plt.show()\n",
    "\n",
    "test_quad_tree_granulation(frame_dir, frame_files)\n",
    "test_quad_tree_granulation(highway_dir, highway_files)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca032952",
   "metadata": {},
   "source": [
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "349f0230",
   "metadata": {},
   "source": [
    "# Rough entropy based threshold calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81d2dbb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_optimal_threshold(image, granules, prev_threshold=None, base=2):\n",
    "    max_gray = int(np.max(image))\n",
    "    min_gray = int(np.min(image))\n",
    "    gray_range = max_gray - min_gray + 1\n",
    "\n",
    "    object_lower = np.zeros(gray_range, dtype=np.float64)\n",
    "    object_upper = np.zeros(gray_range, dtype=np.float64)\n",
    "    background_lower = np.zeros(gray_range, dtype=np.float64)\n",
    "    background_upper = np.zeros(gray_range, dtype=np.float64)\n",
    "\n",
    "    if prev_threshold is not None:\n",
    "        start_threshold = max(min_gray, prev_threshold - 10)\n",
    "        end_threshold = min(max_gray, prev_threshold + 10)\n",
    "    else:\n",
    "        start_threshold = min_gray\n",
    "        end_threshold = max_gray\n",
    "\n",
    "    for (x, y, w, h, *_ ) in granules:\n",
    "        patch = image[y:y+h, x:x+w]\n",
    "        if patch.size == 0:\n",
    "            continue\n",
    "        min_g = int(np.min(patch))\n",
    "        max_g = int(np.max(patch))\n",
    "        size = w * h\n",
    "\n",
    "        for j in range(max_g, end_threshold + 1):\n",
    "            idx = j - min_gray\n",
    "            object_lower[idx] += size\n",
    "\n",
    "        for j in range(min_g, end_threshold + 1):\n",
    "            idx = j - min_gray\n",
    "            object_upper[idx] += size\n",
    "\n",
    "        for j in range(start_threshold, min_g + 1):\n",
    "            idx = j - min_gray\n",
    "            background_lower[idx] += size\n",
    "\n",
    "        for j in range(start_threshold, max_g + 1):\n",
    "            idx = j - min_gray\n",
    "            background_upper[idx] += size\n",
    "\n",
    "    rough_entropy = np.full(gray_range, -np.inf, dtype=np.float64)\n",
    "\n",
    "    for l in range(start_threshold, end_threshold + 1):\n",
    "        idx = l - min_gray\n",
    "        obj_l = object_lower[idx]\n",
    "        obj_u = object_upper[idx]\n",
    "        bg_l = background_lower[idx]\n",
    "        bg_u = background_upper[idx]\n",
    "\n",
    "        obj_rough = 1 - obj_l / obj_u if obj_u > 0 else 1\n",
    "        bg_rough = 1 - bg_l / bg_u if bg_u > 0 else 1\n",
    "\n",
    "        obj_entropy = 1.0 if obj_rough <= 1/base else obj_rough * np.log(obj_rough) / np.log(base)\n",
    "        bg_entropy = 1.0 if bg_rough <= 1/base else bg_rough * np.log(bg_rough) / np.log(base)\n",
    "\n",
    "        rough_entropy[idx] = - (base / 2) * (obj_entropy + bg_entropy)\n",
    "\n",
    "    best_idx = np.argmax(rough_entropy[start_threshold - min_gray : end_threshold - min_gray + 1])\n",
    "    T_star = start_threshold + best_idx\n",
    "\n",
    "    return T_star, rough_entropy[start_threshold - min_gray : end_threshold - min_gray + 1]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95d0d82c",
   "metadata": {},
   "source": [
    "# Rough entropy test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f537e55",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_segmentation(image, threshold):\n",
    "    binary_mask = (image >= threshold).astype(np.uint8) * 255\n",
    "\n",
    "    kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (3, 3))\n",
    "    opened = cv2.morphologyEx(binary_mask, cv2.MORPH_OPEN, kernel)\n",
    "    cleaned_mask = cv2.morphologyEx(opened, cv2.MORPH_CLOSE, kernel)\n",
    "\n",
    "\n",
    "    plt.figure(figsize=(18, 5))\n",
    "\n",
    "    plt.subplot(1, 3, 1)\n",
    "    plt.imshow(image, cmap='gray')\n",
    "    plt.title(\"Oryginalny obraz\")\n",
    "    plt.axis(\"off\")\n",
    "\n",
    "    plt.subplot(1, 3, 2)\n",
    "    plt.imshow(255 - binary_mask, cmap='gray')\n",
    "    plt.title(f\"Segmentacja (bez filtracji) - T*={threshold}\")\n",
    "    plt.axis(\"off\")\n",
    "\n",
    "    plt.subplot(1, 3, 3)\n",
    "    plt.imshow(255 - cleaned_mask, cmap='gray')\n",
    "    plt.title(\"Segmentacja po filtracji (morph open)\")\n",
    "    plt.axis(\"off\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def test_rough_entropy(image, granules):\n",
    "    T_star, _ = compute_optimal_threshold(image, granules)\n",
    "    print(f\"Optimal threshold T* = {T_star}\")\n",
    "    visualize_segmentation(image, T_star)\n",
    "\n",
    "image = cv2.imread(os.path.join(frame_dir, frame_files[0]), cv2.IMREAD_GRAYSCALE)\n",
    "granules = quad_tree_granulation(image)\n",
    "test_rough_entropy(image, granules)\n",
    "image = cv2.imread(os.path.join(highway_dir, highway_files[0]), cv2.IMREAD_GRAYSCALE)\n",
    "granules = quad_tree_granulation(image)\n",
    "test_rough_entropy(image, granules)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9919853a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_segmentation(pred_mask, gt_mask):\n",
    "    pred_flat = pred_mask.flatten()\n",
    "    gt_flat = gt_mask.flatten()\n",
    "\n",
    "    return {\n",
    "        'accuracy': np.mean(pred_flat == gt_flat),\n",
    "        'precision': precision_score(gt_flat, pred_flat, zero_division=0),\n",
    "        'recall': recall_score(gt_flat, pred_flat, zero_division=0),\n",
    "        'f1': f1_score(gt_flat, pred_flat, zero_division=0),\n",
    "        'iou': jaccard_score(gt_flat, pred_flat, zero_division=0),\n",
    "    }\n",
    "\n",
    "def load_ground_truth(gt_path):\n",
    "    gt = cv2.imread(gt_path, cv2.IMREAD_GRAYSCALE)\n",
    "    return (gt == 255).astype(np.uint8)  \n",
    "\n",
    "def evaluate_all_frames(frame_files, gt_dir, frame_dir):\n",
    "    results = []\n",
    "    kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (3, 3))\n",
    "\n",
    "    for fname in frame_files[:100]:  \n",
    "        img_path = os.path.join(frame_dir, fname)\n",
    "        gt_path = os.path.join(gt_dir, fname.replace('in', 'gt').replace('.jpg', '.png'))\n",
    "\n",
    "        image = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
    "        gt_mask = load_ground_truth(gt_path)\n",
    "\n",
    "        if np.sum(gt_mask) == 0:\n",
    "            continue  \n",
    "\n",
    "        granules = quad_tree_granulation(image)\n",
    "        T_star, _ = compute_optimal_threshold(image, granules)\n",
    "\n",
    "        binary_mask = (image >= T_star).astype(np.uint8) * 255\n",
    "        opened = cv2.morphologyEx(binary_mask, cv2.MORPH_OPEN, kernel)\n",
    "        cleaned_mask = cv2.morphologyEx(opened, cv2.MORPH_CLOSE, kernel)\n",
    "        pred_mask = (cleaned_mask > 0).astype(np.uint8)\n",
    "\n",
    "        pred_flat = pred_mask.flatten()\n",
    "        gt_flat = gt_mask.flatten()\n",
    "\n",
    "        results.append({\n",
    "            'frame': fname,\n",
    "            'accuracy': np.mean(pred_flat == gt_flat),\n",
    "            'precision': precision_score(gt_flat, pred_flat, zero_division=0),\n",
    "            'recall': recall_score(gt_flat, pred_flat, zero_division=0),\n",
    "            'f1': f1_score(gt_flat, pred_flat, zero_division=0),\n",
    "            'iou': jaccard_score(gt_flat, pred_flat, zero_division=0),\n",
    "        })\n",
    "\n",
    "    return pd.DataFrame(results)\n",
    "\n",
    "def metrics(frame_files, gt_dir, frame_dir, name=\"pedestrian\"):\n",
    "    print(f\"ðŸ“Š Obliczanie metryk dla wszystkich klatek dla sekwencji {name}...\")\n",
    "    df_results = evaluate_all_frames(frame_files, gt_dir, frame_dir)\n",
    "    print(\"ðŸ“Š Åšrednie metryki (dla klatek z foregroundem):\")\n",
    "    print(df_results[['accuracy', 'precision', 'recall', 'f1', 'iou']].mean())\n",
    "    return df_results\n",
    "\n",
    "df_results_pedestrian = metrics(frame_files, gt_dir, frame_dir)\n",
    "df_results_highway = metrics(highway_files, gt_highway_dir, highway_dir, name=\"highway\")\n",
    "\n",
    "df_results_pedestrian.to_csv('rough_entropy_results_pedestrian.csv', index=False)\n",
    "df_results_highway.to_csv('rough_entropy_results_highway.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82f1c038",
   "metadata": {},
   "source": [
    "# Temporal Segmentation Through Background Estimation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b687b5dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_small_objects(mask, min_area=100):\n",
    "    num_labels, labels, stats, _ = cv2.connectedComponentsWithStats(mask)\n",
    "    filtered = np.zeros_like(mask)\n",
    "    for i in range(1, num_labels):\n",
    "        if stats[i, cv2.CC_STAT_AREA] >= min_area:\n",
    "            filtered[labels == i] = 255\n",
    "    return filtered\n",
    "\n",
    "\n",
    "def estimate_background_mask(f_t, f1, f2, f3, E=3):\n",
    "    f1 = f1.astype(np.uint8)\n",
    "    f2 = f2.astype(np.uint8)\n",
    "    f3 = f3.astype(np.uint8)\n",
    "    f_t = f_t.astype(np.uint8)\n",
    "\n",
    "    a = np.maximum.reduce([f1, f2, f3])\n",
    "    c = np.minimum.reduce([f1, f2, f3])\n",
    "    b = np.median(np.stack([f1, f2, f3]), axis=0).astype(np.uint8)\n",
    "\n",
    "    mu = (a + 4 * b + c) / 6\n",
    "    sigma = (a - c) / 6\n",
    "    sigma[sigma == 0] = 1 \n",
    "\n",
    "    diff = np.abs(f_t.astype(np.float32) - mu.astype(np.float32))\n",
    "    fg_mask = (diff > E * sigma).astype(np.uint8) * 255\n",
    "\n",
    "    kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (3, 3))\n",
    "    opened = cv2.morphologyEx(fg_mask, cv2.MORPH_OPEN, kernel)\n",
    "    cleaned = cv2.morphologyEx(opened, cv2.MORPH_CLOSE, kernel)\n",
    "\n",
    "    return filter_small_objects(cleaned, min_area=80)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f991447",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8309260b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_gray_frame(index, frame_dir, frame_files):\n",
    "    path = os.path.join(frame_dir, frame_files[index])\n",
    "    return cv2.imread(path, cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "def test_background_estimation(frame_dir, frame_files, gt_dir, t=0, E=3, min_area=100):\n",
    "    frame0 = load_gray_frame(t, frame_dir, frame_files)\n",
    "    frame1 = load_gray_frame(t - 1, frame_dir, frame_files)\n",
    "    frame2 = load_gray_frame(t - 2, frame_dir, frame_files)\n",
    "    frame3 = load_gray_frame(t - 3, frame_dir, frame_files)\n",
    "\n",
    "    temporal_mask = estimate_background_mask(frame0, frame1, frame2, frame3, E=E)\n",
    "\n",
    "    granules = quad_tree_granulation(frame0)\n",
    "    T_star, _ = compute_optimal_threshold(frame0, granules)\n",
    "\n",
    "    binary_mask = (frame0 >= T_star).astype(np.uint8) * 255\n",
    "    kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (3, 3))\n",
    "    opened = cv2.morphologyEx(binary_mask, cv2.MORPH_OPEN, kernel)\n",
    "    spatial_mask = cv2.morphologyEx(opened, cv2.MORPH_CLOSE, kernel)\n",
    "\n",
    "    fused_mask = np.logical_and(spatial_mask > 0, temporal_mask > 0).astype(np.uint8) * 255\n",
    "\n",
    "    gt_file = frame_files[t].replace('in', 'gt').replace('.jpg', '.png')\n",
    "    gt_path = os.path.join(gt_dir, gt_file)\n",
    "    \n",
    "    plt.figure(figsize=(18, 5))\n",
    "\n",
    "    plt.subplot(1, 4, 1)\n",
    "    plt.imshow(frame0, cmap='gray')\n",
    "    plt.title(f\"Klatka f_t (#{t + 600})\")\n",
    "    plt.axis(\"off\")\n",
    "\n",
    "    plt.subplot(1, 4, 2)\n",
    "    plt.imshow(spatial_mask, cmap='gray')\n",
    "    plt.title(f\"Maska spatial (T*={T_star})\")\n",
    "    plt.axis(\"off\")\n",
    "\n",
    "    plt.subplot(1, 4, 3)\n",
    "    plt.imshow(temporal_mask * 255, cmap='gray')\n",
    "    plt.title(\"Maska temporal\")\n",
    "    plt.axis(\"off\")\n",
    "\n",
    "    plt.subplot(1, 4, 4)\n",
    "    plt.imshow(fused_mask * 255, cmap='gray')\n",
    "    plt.title(\"Fuzja maski\")\n",
    "    plt.axis(\"off\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "test_background_estimation(frame_dir, frame_files, gt_dir, t=0, E=3, min_area=100)\n",
    "test_background_estimation(highway_dir, highway_files, gt_highway_dir, t=0, E=3, min_area=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca8334dc",
   "metadata": {},
   "source": [
    "### test na wielu klatkach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4e63345",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_gray(path):\n",
    "    return cv2.imread(path, cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "def load_ground_truth(gt_path):\n",
    "    gt = load_gray(gt_path)\n",
    "    return (gt == 255).astype(np.uint8)\n",
    "\n",
    "def evaluate(gt_mask, pred_mask):\n",
    "    gt_flat = gt_mask.flatten()\n",
    "    pred_flat = pred_mask.flatten()\n",
    "    return {\n",
    "        'accuracy': np.mean(pred_flat == gt_flat),\n",
    "        'precision': precision_score(gt_flat, pred_flat, zero_division=0),\n",
    "        'recall': recall_score(gt_flat, pred_flat, zero_division=0),\n",
    "        'f1': f1_score(gt_flat, pred_flat, zero_division=0),\n",
    "        'iou': jaccard_score(gt_flat, pred_flat, zero_division=0)\n",
    "    }\n",
    "\n",
    "def filter_small_objects(mask, min_area=100):\n",
    "    num_labels, labels, stats, _ = cv2.connectedComponentsWithStats(mask)\n",
    "    filtered = np.zeros_like(mask)\n",
    "    for i in range(1, num_labels):\n",
    "        if stats[i, cv2.CC_STAT_AREA] >= min_area:\n",
    "            filtered[labels == i] = 255\n",
    "    return filtered\n",
    "\n",
    "def estimate_background_mask(f_t, f1, f2, f3, E=3):\n",
    "    a = np.maximum(np.maximum(f1, f2), f3)\n",
    "    c = np.minimum(np.minimum(f1, f2), f3)\n",
    "    b = np.median(np.stack([f1, f2, f3]), axis=0)\n",
    "    mu = (a + 4 * b + c) / 6\n",
    "    sigma = (a - c) / 6\n",
    "    diff = np.abs(f_t.astype(np.float32) - mu.astype(np.float32))\n",
    "    fg_mask = (diff > E * sigma).astype(np.uint8)\n",
    "    kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (3,3))\n",
    "    opened = cv2.morphologyEx(fg_mask, cv2.MORPH_OPEN, kernel)\n",
    "    closed = cv2.morphologyEx(opened, cv2.MORPH_CLOSE, kernel)\n",
    "    return filter_small_objects(closed, min_area=120)\n",
    "\n",
    "def multi_frame_test(frame_dir, frame_files, gt_dir, t):\n",
    "    f_paths = [os.path.join(frame_dir, frame_files[t - i]) for i in range(3, 0, -1)]\n",
    "    f_t_path = os.path.join(frame_dir, frame_files[t])\n",
    "    gt_path = os.path.join(gt_dir, frame_files[t].replace('in', 'gt').replace('.jpg', '.png'))\n",
    "    f1, f2, f3 = [load_gray(p) for p in f_paths]\n",
    "    f_t = load_gray(f_t_path)\n",
    "    gt_mask = load_ground_truth(gt_path)\n",
    "\n",
    "    temporal_mask = estimate_background_mask(f_t, f1, f2, f3, E=4)\n",
    "\n",
    "    granules = quad_tree_granulation(f_t)\n",
    "    T_star, _ = compute_optimal_threshold(f_t, granules)\n",
    "    binary_mask = (f_t >= T_star).astype(np.uint8) * 255\n",
    "    kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (3, 3))\n",
    "    opened = cv2.morphologyEx(binary_mask, cv2.MORPH_OPEN, kernel)\n",
    "    spatial_mask = cv2.morphologyEx(opened, cv2.MORPH_CLOSE, kernel)\n",
    "\n",
    "    plt.figure(figsize=(24, 5))\n",
    "    plt.subplot(1, 4, 1)\n",
    "    plt.imshow(f_t, cmap='gray')\n",
    "    plt.title(f\"Klatka f_t (#{t + 600})\")\n",
    "    plt.axis(\"off\")\n",
    "    plt.subplot(1, 4, 2)\n",
    "    plt.imshow(255 - spatial_mask, cmap='gray')\n",
    "    plt.title(f\"Maska spatial (T*={T_star})\")\n",
    "    plt.axis(\"off\")\n",
    "    plt.subplot(1, 4, 3)\n",
    "    plt.imshow(temporal_mask, cmap='gray')\n",
    "    plt.title(\"Maska temporal\")\n",
    "    plt.axis(\"off\")\n",
    "    fused_mask = np.logical_and(spatial_mask > 0, temporal_mask > 0).astype(np.uint8) * 255\n",
    "    plt.subplot(1, 4, 4)\n",
    "    plt.imshow(fused_mask, cmap='gray')\n",
    "    plt.title(\"Fuzja (spatial âˆ© temporal)\")\n",
    "    plt.axis(\"off\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    metrics = evaluate(gt_mask, (fused_mask > 0).astype(np.uint8))\n",
    "\n",
    "    print(f\"ðŸ“Š Metryki dla klatki #{t}:\")\n",
    "    for k, v in metrics.items():\n",
    "        print(f\"{k:10s}: {v:.4f}\")\n",
    "\n",
    "    results = []\n",
    "    for i in range(3, len(frame_files)):\n",
    "        paths = [os.path.join(frame_dir, frame_files[j]) for j in range(i - 3, i)]\n",
    "        f_t_path = os.path.join(frame_dir, frame_files[i])\n",
    "        gt_path = os.path.join(gt_dir, frame_files[i].replace('in', 'gt').replace('.jpg', '.png'))\n",
    "\n",
    "        f1, f2, f3 = [load_gray(p) for p in paths]\n",
    "        f_t = load_gray(f_t_path)\n",
    "        gt_mask = load_ground_truth(gt_path)\n",
    "        if np.sum(gt_mask) == 0:\n",
    "            continue\n",
    "\n",
    "        mask = estimate_background_mask(f_t, f1, f2, f3, E=3)\n",
    "        pred_mask = (mask > 0).astype(np.uint8)\n",
    "        metrics = evaluate(gt_mask, pred_mask)\n",
    "        metrics['frame'] = frame_files[i]\n",
    "        results.append(metrics)\n",
    "\n",
    "    df = pd.DataFrame(results)\n",
    "    print(\"\\nðŸ“‰ Åšrednie metryki (dla klatek z foregroundem):\")\n",
    "    print(df[['accuracy', 'precision', 'recall', 'f1', 'iou']].mean().round(4))\n",
    "    df.to_csv('3point_temporal_results.csv', index=False)\n",
    "\n",
    "multi_frame_test(frame_dir, frame_files, gt_dir, t=0)\n",
    "multi_frame_test(highway_dir, highway_files, gt_highway_dir, t=0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c108cbcc",
   "metadata": {},
   "source": [
    "# Algorithm for tracking "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11160afc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def center(box):\n",
    "    x1, y1, x2, y2 = box\n",
    "    return ((x1 + x2) / 2, (y1 + y2) / 2)\n",
    "\n",
    "def init_tracking(groundtruth_array):\n",
    "    prev_prev_tracker = groundtruth_array[0]\n",
    "    prev_tracker = groundtruth_array[1]\n",
    "\n",
    "    cx0, cy0 = center(prev_prev_tracker)\n",
    "    cx1, cy1 = center(prev_tracker)\n",
    "\n",
    "    dx = -(cx1 - cx0)\n",
    "    dy = -(cy1 - cy0)\n",
    "    s = np.sqrt((cx1 - cx0)**2 + (cy1 - cy0)**2)\n",
    "\n",
    "    tracker = {\n",
    "        'prev_threshold': None,\n",
    "        'prev_tracker': prev_tracker,\n",
    "        'prev_prev_tracker': prev_prev_tracker,\n",
    "        'dx': dx,\n",
    "        'dy': dy,\n",
    "        's': s\n",
    "    }\n",
    "    return tracker\n",
    "\n",
    "gt_array_1 = [\n",
    "    [100, 100, 140, 140],  \n",
    "    [110, 110, 150, 150]   \n",
    "]\n",
    "\n",
    "tracker = init_tracking(gt_array_1)\n",
    "\n",
    "print(\"dx:\", tracker['dx'])\n",
    "print(\"dy:\", tracker['dy'])\n",
    "print(\"s:\", tracker['s'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a60631f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_speed_dx_dy(gt_array):\n",
    "    num_frames_to_check = 10\n",
    "\n",
    "    assert len(gt_array) >= num_frames_to_check, \"Za maÅ‚o ramek GT\"\n",
    "    for i in range(1, num_frames_to_check):\n",
    "        tracker = init_tracking(gt_array[i-1:i+1])\n",
    "\n",
    "        predicted_box = [\n",
    "            int(round(gt_array[i][0] + tracker['dx'])),\n",
    "            int(round(gt_array[i][1] + tracker['dy'])),\n",
    "            int(round(gt_array[i][2] + tracker['dx'])),\n",
    "            int(round(gt_array[i][3] + tracker['dy']))\n",
    "        ]\n",
    "\n",
    "        img = colour_images_array[i + 1].copy()\n",
    "\n",
    "        cv2.rectangle(img, (gt_array[i+1][0], gt_array[i+1][1]),\n",
    "                           (gt_array[i+1][2], gt_array[i+1][3]), (0, 255, 0), 2)\n",
    "        cv2.rectangle(img, (predicted_box[0], predicted_box[1]),\n",
    "                           (predicted_box[2], predicted_box[3]), (255, 0, 0), 2)\n",
    "\n",
    "        text = f\"dx: {tracker['dx']:.1f}, dy: {tracker['dy']:.1f}, s: {tracker['s']:.1f}\"\n",
    "        cv2.putText(img, text, (10, 25), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 255), 2)\n",
    "\n",
    "        plt.figure(figsize=(6, 6))\n",
    "        plt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
    "        plt.title(f\"Frame {i+1} vs pred na {i+2}\")\n",
    "        plt.axis(\"off\")\n",
    "        plt.show()\n",
    "\n",
    "test_speed_dx_dy(gt_array)\n",
    "\n",
    "def test_speed_dx_dy_highway(gt_array):\n",
    "    num_frames_to_check = 10\n",
    "\n",
    "    assert len(gt_array) >= num_frames_to_check, \"Za maÅ‚o ramek GT\"\n",
    "    for i in range(1, num_frames_to_check):\n",
    "        tracker = init_tracking(gt_array[i-1:i+1])\n",
    "\n",
    "        predicted_box = [\n",
    "            int(round(gt_array[i][0] + tracker['dx'])),\n",
    "            int(round(gt_array[i][1] + tracker['dy'])),\n",
    "            int(round(gt_array[i][2] + tracker['dx'])),\n",
    "            int(round(gt_array[i][3] + tracker['dy']))\n",
    "        ]\n",
    "\n",
    "        img = highway_colour_images_array[i + 1].copy()\n",
    "\n",
    "        cv2.rectangle(img, (gt_array[i+1][0], gt_array[i+1][1]),\n",
    "                           (gt_array[i+1][2], gt_array[i+1][3]), (0, 255, 0), 2)\n",
    "        cv2.rectangle(img, (predicted_box[0], predicted_box[1]),\n",
    "                           (predicted_box[2], predicted_box[3]), (255, 0, 0), 2)\n",
    "\n",
    "        text = f\"dx: {tracker['dx']:.1f}, dy: {tracker['dy']:.1f}, s: {tracker['s']:.1f}\"\n",
    "        cv2.putText(img, text, (10, 25), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 255), 2)\n",
    "\n",
    "        plt.figure(figsize=(6, 6))\n",
    "        plt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
    "        plt.title(f\"Frame {i+1} vs pred na {i+2}\")\n",
    "        plt.axis(\"off\")\n",
    "        plt.show()\n",
    "\n",
    "test_speed_dx_dy_highway(highway_gt_array)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5097c335",
   "metadata": {},
   "source": [
    "# Object tracking iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bd24cf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def improved_semi_supervised_object_tracking(gray_images_array, colour_images_array, groundtruth_array, min_iou_threshold=0.1, max_lost=5):\n",
    "    def compute_iou(boxA, boxB):\n",
    "        xA = max(boxA[0], boxB[0])\n",
    "        yA = max(boxA[1], boxB[1])\n",
    "        xB = min(boxA[2], boxB[2])\n",
    "        yB = min(boxA[3], boxB[3])\n",
    "        interW = max(0, xB - xA)\n",
    "        interH = max(0, yB - yA)\n",
    "        interArea = interW * interH\n",
    "        boxAArea = (boxA[2] - boxA[0]) * (boxA[3] - boxA[1])\n",
    "        boxBArea = (boxB[2] - boxB[0]) * (boxB[3] - boxB[1])\n",
    "        unionArea = boxAArea + boxBArea - interArea\n",
    "        return interArea / unionArea if unionArea > 0 else 0\n",
    "\n",
    "    def predict_tracker_position(tracker):\n",
    "        x1, y1, x2, y2 = tracker['prev_tracker']\n",
    "        dx, dy = tracker['dx'], tracker['dy']\n",
    "        return [\n",
    "            int(round(x1 + dx)),\n",
    "            int(round(y1 + dy)),\n",
    "            int(round(x2 + dx)),\n",
    "            int(round(y2 + dy))\n",
    "        ]\n",
    "\n",
    "    results = []\n",
    "    tracker = init_tracking(groundtruth_array)\n",
    "    lost_counter = 0\n",
    "    poor_iou_counter = 0\n",
    "\n",
    "    for idx in range(3, len(gray_images_array)):\n",
    "        gray_img = gray_images_array[idx]\n",
    "        colour_img = colour_images_array[idx]\n",
    "\n",
    "        granules = quad_tree_granulation(gray_img)\n",
    "        new_threshold, _ = compute_optimal_threshold(gray_img, granules, tracker['prev_threshold'])\n",
    "        spatial_mask = (gray_img >= new_threshold).astype(np.uint8)\n",
    "        f_t, f1, f2, f3 = gray_img, gray_images_array[idx - 1], gray_images_array[idx - 2], gray_images_array[idx - 3]\n",
    "        temporal_mask = estimate_background_mask(f_t, f1, f2, f3)\n",
    "\n",
    "        cx0, cy0 = center(tracker['prev_prev_tracker'])\n",
    "        cx1, cy1 = center(tracker['prev_tracker'])\n",
    "        dx, dy = -(cx1 - cx0), -(cy1 - cy0)\n",
    "        s = np.sqrt((cx1 - cx0)**2 + (cy1 - cy0)**2)\n",
    "\n",
    "        Txl, Tyl, Txu, Tyu = tracker['prev_tracker']\n",
    "        exp_x = s * (1.25 if dx > 0 else 0.75)\n",
    "        cont_x = s * (0.75 if dx > 0 else 1.25)\n",
    "        exp_y = s * (1.25 if dy > 0 else 0.75)\n",
    "        cont_y = s * (0.75 if dy > 0 else 1.25)\n",
    "        Txl = int(round(Txl - cont_x))\n",
    "        Txu = int(round(Txu + exp_x))\n",
    "        Tyl = int(round(Tyl - cont_y))\n",
    "        Tyu = int(round(Tyu + exp_y))\n",
    "\n",
    "        h, w = gray_img.shape\n",
    "        Txl, Tyl, Txu, Tyu = max(0, Txl), max(0, Tyl), min(w - 1, Txu), min(h - 1, Tyu)\n",
    "\n",
    "        combined_mask = cv2.bitwise_and(spatial_mask, temporal_mask)\n",
    "        roi_mask = combined_mask[Tyl:Tyu, Txl:Txu]\n",
    "        roi_rgb = colour_img[Tyl:Tyu, Txl:Txu]\n",
    "        R, G, B = roi_rgb[:, :, 0], roi_rgb[:, :, 1], roi_rgb[:, :, 2]\n",
    "        mask_fg = roi_mask > 0\n",
    "\n",
    "        if np.sum(mask_fg) == 0:\n",
    "            lost_counter += 1\n",
    "            predicted = predict_tracker_position(tracker)\n",
    "        else:\n",
    "            lost_counter = 0\n",
    "            mean_R = np.mean(R[mask_fg])\n",
    "            mean_G = np.mean(G[mask_fg])\n",
    "            mean_B = np.mean(B[mask_fg])\n",
    "            max_dev_R = np.max(np.abs(R[mask_fg] - mean_R))\n",
    "            max_dev_G = np.max(np.abs(G[mask_fg] - mean_G))\n",
    "            max_dev_B = np.max(np.abs(B[mask_fg] - mean_B))\n",
    "\n",
    "            mask_rgb = (\n",
    "                (np.abs(R - mean_R) < max_dev_R) &\n",
    "                (np.abs(G - mean_G) < max_dev_G) &\n",
    "                (np.abs(B - mean_B) < max_dev_B) &\n",
    "                (roi_mask > 0)\n",
    "            ).astype(np.uint8)\n",
    "\n",
    "            coords = cv2.findNonZero(mask_rgb)\n",
    "            if coords is not None:\n",
    "                x, y, w_, h_ = cv2.boundingRect(coords)\n",
    "                predicted = [Txl + x, Tyl + y, Txl + x + w_, Tyl + y + h_]\n",
    "            else:\n",
    "                lost_counter += 1\n",
    "                predicted = predict_tracker_position(tracker)\n",
    "\n",
    "        results.append(predicted)\n",
    "\n",
    "        if idx < len(groundtruth_array):\n",
    "            iou = compute_iou(predicted, groundtruth_array[idx])\n",
    "            poor_iou_counter = poor_iou_counter + 1 if iou < min_iou_threshold else 0\n",
    "\n",
    "        if lost_counter >= max_lost or poor_iou_counter >= max_lost:\n",
    "            print(f\"ðŸ›‘ Tracker deaktywowany (zgubienie lub niskie IoU przez {max_lost} klatek).\")\n",
    "            break\n",
    "\n",
    "        tracker.update({\n",
    "            'prev_prev_tracker': tracker['prev_tracker'],\n",
    "            'prev_tracker': predicted,\n",
    "            'prev_threshold': new_threshold,\n",
    "            'dx': dx,\n",
    "            'dy': dy,\n",
    "            's': s\n",
    "        })\n",
    "\n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e22007c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mask_to_bbox(mask):\n",
    "    coords = cv2.findNonZero(mask.astype(np.uint8))\n",
    "    if coords is not None:\n",
    "        x, y, w, h = cv2.boundingRect(coords)\n",
    "        return [x, y, x + w, y + h]\n",
    "    else:\n",
    "        return [0, 0, 0, 0]  \n",
    "\n",
    "\n",
    "groundtruth_array = []\n",
    "\n",
    "for fname in frame_files:\n",
    "    gt_path = os.path.join(gt_dir, fname.replace('in', 'gt').replace('.jpg', '.png'))\n",
    "    gt_mask = load_ground_truth(gt_path)  \n",
    "    bbox = mask_to_bbox(gt_mask)\n",
    "    groundtruth_array.append(bbox)\n",
    "\n",
    "\n",
    "def bbox_iou(boxA, boxB):\n",
    "    xA = max(boxA[0], boxB[0])\n",
    "    yA = max(boxA[1], boxB[1])\n",
    "    xB = min(boxA[2], boxB[2])\n",
    "    yB = min(boxA[3], boxB[3])\n",
    "\n",
    "    interW = max(0, xB - xA)\n",
    "    interH = max(0, yB - yA)\n",
    "    interArea = interW * interH\n",
    "\n",
    "    boxAArea = (boxA[2] - boxA[0]) * (boxA[3] - boxA[1])\n",
    "    boxBArea = (boxB[2] - boxB[0]) * (boxB[3] - boxB[1])\n",
    "\n",
    "    unionArea = boxAArea + boxBArea - interArea\n",
    "\n",
    "    return interArea / unionArea if unionArea > 0 else 0\n",
    "\n",
    "\n",
    "def center_distance(boxA, boxB):\n",
    "    cxA = (boxA[0] + boxA[2]) / 2\n",
    "    cyA = (boxA[1] + boxA[3]) / 2\n",
    "    cxB = (boxB[0] + boxB[2]) / 2\n",
    "    cyB = (boxB[1] + boxB[3]) / 2\n",
    "    return np.sqrt((cxA - cxB) ** 2 + (cyA - cyB) ** 2)\n",
    "\n",
    "\n",
    "def test_tracker(gray_images_array, colour_images_array, groundtruth_array, granules):\n",
    "    predicted_boxes = improved_semi_supervised_object_tracking(\n",
    "    gray_images_array,\n",
    "    colour_images_array,\n",
    "    groundtruth_array,\n",
    "    min_iou_threshold=0.1,  \n",
    "    max_lost=10              \n",
    "    )\n",
    "\n",
    "    ious = []\n",
    "    distances = []\n",
    "    for i, pred in enumerate(predicted_boxes):\n",
    "        gt = groundtruth_array[i + 2]\n",
    "    \n",
    "        if gt == [0, 0, 0, 0]:\n",
    "            continue  \n",
    "        \n",
    "        iou = bbox_iou(pred, gt)\n",
    "        dist = center_distance(pred, gt)\n",
    "        ious.append(iou)\n",
    "        distances.append(dist)\n",
    "\n",
    "\n",
    "    print(\"ðŸ“ˆ Tracker performance:\")\n",
    "    print(f\"Mean IoU:      {np.mean(ious):.4f}\")\n",
    "    print(f\"Mean Distance: {np.mean(distances):.2f} px\")\n",
    "\n",
    "    return ious, distances, predicted_boxes\n",
    "\n",
    "granules = quad_tree_granulation(gray_images_array[0])\n",
    "ious, distances, preds = test_tracker(gray_images_array, colour_images_array, groundtruth_array, granules)\n",
    "\n",
    "def test_tracker_highway(gray_images_array, colour_images_array, groundtruth_array, granules):\n",
    "    predicted_boxes = improved_semi_supervised_object_tracking(\n",
    "        gray_images_array,\n",
    "        colour_images_array,\n",
    "        groundtruth_array,\n",
    "        min_iou_threshold=0.1,  \n",
    "        max_lost=10              \n",
    "    )\n",
    "\n",
    "    ious = []\n",
    "    distances = []\n",
    "    for i, pred in enumerate(predicted_boxes):\n",
    "        gt = groundtruth_array[i + 2]\n",
    "    \n",
    "        if gt == [0, 0, 0, 0]:\n",
    "            continue  \n",
    "        \n",
    "        iou = bbox_iou(pred, gt)\n",
    "        dist = center_distance(pred, gt)\n",
    "        ious.append(iou)\n",
    "        distances.append(dist)\n",
    "\n",
    "    print(\"ðŸ“ˆ Tracker performance (highway):\")\n",
    "    print(f\"Mean IoU:      {np.mean(ious):.4f}\")\n",
    "    print(f\"Mean Distance: {np.mean(distances):.2f} px\")\n",
    "\n",
    "    return ious, distances, predicted_boxes\n",
    "\n",
    "granules_highway = quad_tree_granulation(highway_gray_images_array[0])\n",
    "ious_highway, distances_highway, preds_highway = test_tracker_highway(highway_gray_images_array, highway_colour_images_array, highway_gt_array, granules_highway)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b5059cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_tracker_metrics(ious, distances, save_path=None):\n",
    "    frames = np.arange(len(ious))\n",
    "\n",
    "    plt.figure(figsize=(12, 5))\n",
    "\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(frames, ious, marker='o', color='blue', label='IoU')\n",
    "    plt.title(\"IoU per Frame\")\n",
    "    plt.xlabel(\"Frame Index\")\n",
    "    plt.ylabel(\"IoU\")\n",
    "    plt.ylim(0, 1)\n",
    "    plt.grid(True)\n",
    "    plt.legend()\n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(frames, distances, marker='s', color='orange', label='Center Distance')\n",
    "    plt.title(\"Center Distance per Frame\")\n",
    "    plt.xlabel(\"Frame Index\")\n",
    "    plt.ylabel(\"Distance [px]\")\n",
    "    plt.grid(True)\n",
    "    plt.legend()\n",
    "\n",
    "    plt.tight_layout()\n",
    "\n",
    "    if save_path:\n",
    "        plt.savefig(save_path, dpi=150)\n",
    "        print(f\"âœ… Wykres zapisany do: {save_path}\")\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "plot_tracker_metrics(ious, distances)\n",
    "plot_tracker_metrics(ious_highway, distances_highway, save_path='tracker_metrics_highway.png')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70fd0786",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_tracking_video(output_path, colour_images_array, predicted_boxes, fps=10):\n",
    "    h, w, _ = colour_images_array[0].shape\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "    out = cv2.VideoWriter(output_path, fourcc, fps, (w, h))\n",
    "\n",
    "    for i in range(len(predicted_boxes)):\n",
    "        frame = colour_images_array[i + 3].copy()  \n",
    "\n",
    "        print(f'frame nr{ i + 3} - {predicted_boxes[i]}')\n",
    "\n",
    "        x1, y1, x2, y2 = predicted_boxes[i]\n",
    "        cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
    "        cv2.putText(frame, f\"Frame {i + 3}\", (10, 25), cv2.FONT_HERSHEY_SIMPLEX,\n",
    "                    0.8, (0, 255, 255), 2)\n",
    "\n",
    "        out.write(frame)\n",
    "\n",
    "    out.release()\n",
    "    print(f\"ðŸŽ¥ Zapisano plik wideo: {output_path}\")\n",
    "\n",
    "\n",
    "save_tracking_video(\"tracker_output.mp4\", colour_images_array, preds)\n",
    "\n",
    "save_tracking_video(\"tracker_output_highway.mp4\", highway_colour_images_array, preds_highway)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
